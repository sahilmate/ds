import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, multilabel_confusion_matrix

dataset = pd.read_csv("iris.csv")

print("Dataset Summary:\n", dataset.describe())
print("\nFirst 5 rows:\n", dataset.head())
print("\nShape of dataset:", dataset.shape)

X = dataset.iloc[:, :4].values  # All rows, first 4 columns
y = dataset["Species"].values  # All rows, species column

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

sc = StandardScaler()
X_train = sc.fit_transform(X_train)  # feature scaling
X_test = sc.transform(X_test)

classifier = GaussianNB()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

print("\nConfusion Matrix:")
cm = confusion_matrix(y_test, y_pred)
print(cm)

accuracy = accuracy_score(y_test, y_pred)
error_rate = 1 - accuracy
precision = precision_score(y_test, y_pred, average='macro', labels=np.unique(y))
recall = recall_score(y_test, y_pred, average='macro', labels=np.unique(y))
f1 = f1_score(y_test, y_pred, average='macro', labels=np.unique(y))

print(f"Accuracy: {accuracy}")
print(f"Error Rate: {error_rate}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")

# optional
plt.figure(figsize=(6, 4))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(np.unique(y)))
plt.xticks(tick_marks, np.unique(y))
plt.yticks(tick_marks, np.unique(y))
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

print("\nComparison of Actual vs Predicted:")
comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
print(comparison)

correct = np.sum(y_test == y_pred)
total = len(y_test)
print(f"\nConclusion: {correct} out of {total} predictions were correct.")